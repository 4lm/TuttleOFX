import os
import sha
import shutil
import subprocess
import sys
import tarfile
import zipfile
from pprint import pprint

###new
def archive_is_uncompressed(filename, verbose=True):
    import os, tarfile

    real_path = archive_real_path(filename)
    if not os.path.exists(real_path):
        return False

    tar = tarfile.open(real_path)
    
def archive_real_path(filename):
    '''
    Return an archive full path from filename.
    '''
    import os

    return os.path.join(os.environ['BRNDO_ROOT'], 'archive', filename)
    
def check_sha1(real_path, sha1, verbose=True):
    '''
    Compute sha1 from content and compare it to sha1
    '''
    import sha

    with open(real_path, 'r') as f:
        content = f.read()

    s = sha.sha(content).hexdigest()
    if verbose:
        print("Expected {}".format(sha1))
        print("Computed {}".format(s))

    if sha1 != s:
        if verbose:
            print("Sha mismatch !")

        return False

    if verbose:
        print("Sha match.")

    return True

def check_file_size(filename, size):
    '''
    Return 0 if os.stat(filename)'s posix.stat_result.st_size equal size
    actual posix.stat_result.st_size otherwise.
    '''
    import os, stat

    sr = os.stat(filename)
    if sr.st_size != size:
        return sr.st_size

    return 0

def fetch_archive(url, ressource_name, expected_size, from_byte=0, verbose=True):
    '''
    Fetch url into the archive dir as ressource_name
    raise ValueError if ressource size is not expected_size
    '''
    import os, stat, urllib

    real_path = archive_real_path(filename)
    if os.path.exists(real_path):
         current_size = check_file_size(real_path, expected_size)
         if not current_size and os.stat(filename).st_size:
             return
    
    from_byte = util.file_bytes_to_skip(real_path, size, sha1)
    report_hook = None
    if verbose:
        report_hook = urlretrieve_report_hook(url)

    url_opener = urllib.FancyURLopener()
    if from_byte:
        url_opener.addheader('Range', 'bytes={}-{}'.format(from_byte, size))

    url_opener.urlretrieve(url, filename, report_hook)
    current_size = os.stat(filename).st_size
    if current_size != expected_size:
        raise ValueError('Ressource is {} len (expected size {})'\
                         .format(current_size, expected_size))

def file_bytes_to_skip(filename, total_size, sha1=None):
    '''
    Return the number of bytes index to start download for filename
    '''
    import os, stat

    if not is_fetched(filename, total_size):
        return 0

    current_size = os.stat(filename).st_size
    if total_size != current_size:
        return 0 if current_size > size else current_size
    
    if sha1:
        with open(filename, 'r') as f:
            if not check_sha1(f.read(), sha1):
                return 0

    # filename is complete
    return total_size

def is_fetched(filename, total_size, verbose=True):
    '''
    Return True if filename is completely fetched
    False otherwise. (no integrity check)
    '''
    import os

    real_path = archive_real_path(filename)
    if not os.path.exists(real_path):
        return False

    if check_file_size(real_path, total_size):
        return False

    return True

def uncompress_archive(filename, dest_dir, verbose=True):
    '''
    Uncompress filename to dest_dir depending on its' extension.
    '''
    if filename.split('.')[-1] in ['tgz', 'tar.gz']:
        untar(filename, dest_dir, verbose)
        return

    raise NotImplementedError('Cannot determine how to uncompres {}'\
                              .format(repr(filename)))

def untar(filename, verbose=True):
    '''
    Uncompress tar file filename into dest_dir.
    '''
    import os, tarfile

    real_path = archive_real_path(filename)
    dest_dir = os.path.join(os.environ['BRNDO_ROOT'], 'uncompressed', filename)
    tar = tarfile.open(filename)
    if set([s.split('/')[0] for s in t.getnames()]) != 1:
        dest_dir = os.path.join(dest_dir,
                                filename.split('.tgz')[0].split('.tar.gz')[0])

    if not os.path.exists(dest_dir):
        os.makedirs(dest_dir)

    tar.extractall(path=dest_dir)

def update_libs_with_dependencies(libs, all_libs):
    '''
    Return new list consisting of libs plus their dependencies.
    libs is a list of bpkg module.
    '''
    libs_dict = {}
    new_list = set(libs)
    for l in all_libs:
        libs_dict[l.name] = l

    for l in libs:
        print dir(l)
        for d in l.depends_on:
            new_list.add(libs_dict[d])

    return list(new_list)
    

def urlretrieve_report_hook(url):
    '''
    Progress bar urllib.urlretrieve report_hook
    '''
    import functools

    def report_hook(filename, count, block_size, total_size):
        percent = int( count * block_size * 100/total_size )
        progress_bar = '[--------------------]'
        fill = ">" * (count * block_size * (len(progress_bar)-2)/total_size)
        progress_bar = progress_bar.replace('-'*len(fill), fill, 1)
        sys.stdout.write( '\r{} {} % of {}'.format(progress_bar,
                                                   percent, filename))
        sys.stdout.flush()

        if percent >= 100:
            sys.stdout.write('\n')
            sys.stdout.flush()

    return functools.partial(report_hook, url)
###/new

def format_lib_as_script(lib, base_lib_dir):
    '''
    Return a string describing a package as a python script.
    None if template file is not found.
    Support Template : v0.1
    '''
    destination_dir = base_lib_dir
    template_filename = os.path.join(destination_dir, '_template.p_')

    if not os.path.exists(template_filename):
        print "**ERROR** - Template file not found."
        return None

    with open(template_filename, 'r') as f:
        template = f.read()

    return template.format(lib_name          = lib.get('name', ''),
                           lib_url           = lib.get('url', ''),
                           lib_sha           = lib.get('sha', ''),
                           lib_depends_on    = lib.get('depends_on', []),
                           # Restoring values that shouldn't be formatted now.
                           name='{}', url='{}', sha='{}',
                           depends_on='{}')

def execute_command(lib, cmd_key, basedir, verbose=False):
    '''
    Execute lib['cmd_key'] command in basedir/lib['name'].
    If verbose is True, print command output on sys.stdout.
    Return True on success, False otherwise.
    '''
    has_no_exception = True
    stdout_file = sys.stdout
    stderr_file = sys.stderr
    current_dir = os.path.abspath(os.path.curdir)
    try:
        if not verbose:
            stdout_file = open('/dev/null', 'w')
            stderr_file = stdout_file

        os.chdir(os.path.join(basedir, lib['name']))
        subprocess.call(lib[cmd_key].split(),
                        stdout=stdout_file,
                        stderr=stderr_file)

    except:
        import traceback
        print "**ERROR** - execute_command exception."
        print traceback.format_exc(sys.exc_info()[2])
        has_no_exception = False

    finally:
        os.chdir(current_dir)
        if stdout_file is not sys.stdout:
            stdout_file.close()

        return has_no_exception

def order_by_topology(graph):
    '''
    Return a topology ordered node_name list, if graph has no cycles
    graph is a dict such as {'node_name':['dependency_name', ...], ...}
    
    http://en.wikipedia.org/wiki/Topological_sort
    L <- Empty list that will contain the sorted elements
    S <- Set of all nodes with no incoming edges
    while S is non-empty do
      remove a node n from S
      insert n into L
      for each node m with an edge e from n to m do
        remove edge e from the graph
        if m has no other incoming edges then
            insert m into S
    if graph has edges then
      return error (graph has at least one cycle)
    else 
      return L (a topologically sorted order)
    '''
    graph_copy = dict(graph)
    for n in graph_copy:
        graph_copy[n] = list(graph_copy[n])

    ordered_list = []
    node_without_edges = [n for n in graph_copy if not len(graph_copy[n])]
    while node_without_edges:
        n = node_without_edges.pop()
        ordered_list.append(n)
        for m in [m for m in graph_copy if n in graph_copy[m]]:
            graph_copy[m].remove(n)
            if not graph_copy[m]:
                node_without_edges.append(m)

    graph_has_cycle = False
    for n in graph_copy:
        if graph_copy[n] != []:
            graph_has_cycle = True

    if graph_has_cycle:
        raise RuntimeError("Graph cycle(s) detected.")

    return ordered_list

def test_order_by_topology():
    '''
    Test the order_by_topology function.
    Return True if all tests were successfull, False otherwise.
    '''
    return_value = True
    nodes = {
    'a': ['b', 'c', 'd'],
    'b': ['e'],
    'c': ['e'],
    'd': ['c', 'f'],
    'e': [],
    'f': [],
    }
    print '-- '
    print test_order_by_topology.__doc__
    print "Testing success."
    print "Order graph"
    print '{'
    for n in sorted(nodes.keys()):
        print "  '{node}': {dependencies},".format(node=n, dependencies=nodes[n])

    print '}'
    build_sequence = order_by_topology(nodes)
    print "Testing build sequence", build_sequence
    built_nodes = []
    for n in build_sequence:
        for d in nodes[n]:
            if d not in built_nodes:
                print "**ERROR** - {} dependency from {} not satisfied.".format(n, d)
                print "Built nodes", built_nodes, "remains", [n for n in nodes.keys()
                                                              if n not in built_nodes]
                return_value = False
                break

        built_nodes.append(n)

    if sorted(built_nodes) == sorted(nodes.keys()):
        print "Ok - All nodes were succesffully built."

    #test with cycling graph
    nodes = {
        'a': ['b', 'c', 'd'],
        'b': ['e'],
        'c': ['e'],
        'd': ['c', 'f'],
        'e': ['a'],
        'f': [],
        }
    print "Testing Failure."
    print "Graph"
    print '{'
    for n in sorted(nodes.keys()):
        print "  '{node}': {dependencies},".format(node=n, dependencies=nodes[n])
    print '}'

    try:
        build_sequence = order_by_topology(nodes)

    except RuntimeError, e:
        print 'Ok - exception', e
        return return_value

    print '**ERROR** - No exception raised.'
    return_value = False
    return return_value
    
def shacheck(filename, sha_str, verbose=False):
    '''
    Compute SHA1 for filename and compare it to sha_str.
    Return True if sha match, False otherwise.
    '''
    with open(filename, 'rb') as f:
        current_sha = sha.sha(f.read()).hexdigest()

    if verbose:
        print "Sha Expected :", sha_str
        print "Sha Current  :", current_sha

    if current_sha == sha_str:
        return True

    return False

def get_known_extensions(filename):
    known_extensions = [
        'tar',
        'tar.gz', 'tgz',
        'tar.bz2',
        'zip',
        'exe',
        ]
    return [f for f in known_extensions if filename.endswith(f)]

def extract(filename, in_new_directory, libname, folder):
    ext = get_known_extensions(filename)[0]

    if ext == 'tar.gz' :
        tar = tarfile.open(filename, 'r:*')
        tar.extractall(folder)
        out_dir = tar.getnames()[0]
        
    if ext == 'tar.bz2' :
        tar = tarfile.open(filename, 'r:*')
        tar.extractall(folder)
        out_dir = tar.getnames()[0]

    if ext == 'tgz' :
        tar = tarfile.open(filename, 'r:*')
        tar.extractall(folder)
        out_dir = tar.getnames()[0]
        
    if ext == 'zip' :
        zip = zipfile.ZipFile(filename, 'r')
        if in_new_directory == True : folder += filename[:-len(ext)-1]
        zip.extractall( folder )
        out_dir = zip.namelist()[0]

    if ext == 'exe' :
        fileToRun = filename + ".exe"
        os.startfile( fileToRun )

    if not os.path.exists(os.path.join(os.getcwd(), folder, libname)):
        os.mkdir(os.path.join(os.getcwd(), folder, libname))

    if not os.path.isdir(os.path.join(folder, out_dir)):
        out_dir = os.path.dirname(out_dir)

    if out_dir != libname:
        if os.path.exists(os.path.join(folder, libname)):
            shutil.rmtree(os.path.join(folder, libname))

        os.rename(os.path.join(folder, out_dir),
                  os.path.join(folder, libname))

if __name__ == "__main__":
    if test_order_by_topology():
        print "Tests Ok."
    else:
        print "Tests Failed."
